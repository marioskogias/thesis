\chapter{Linux Trace Toolkit - next generation (LTTng)}\label{ch:lttng}

In this chapter we analyze Linux Trace Toolkin - next generation (LTTng), which
was our choice for BlkKin's tracing backend, and we describe its internal
characteristics that led us to using it. Specifically, we give an overall
outline of its architecture and basic notions in Section
\ref{sec:lttng-overview}. Then, we describe the buffering scheme used both for
kernel and user space (Section \ref{sec:buffers}) and we continue by citing
kernel and use space implementation mechanism in Sections
\ref{sec:kernel-tracing}, \ref{sec:user-tracing}. Finally we cite the tracing
format used by LTTng (Section \ref{sec:ctf}) and the mechanism for live tracing
in Section \label{sec:relayd}.

\section{Overview}\label{sec:lttng-overview}

Linux Trace Toolkin - next generation is the successor of Linux Trace Toolkit.
It started as the Mathew Desnoyer's PhD dissertation \cite{desnoyer} in École
Polytechnique de Montréal. Since then, it is maintained by EfficiOS
Inc\footnote{http://www.efficios.com/} and the DORSAL lab in  École
Polytechnique de Montréal.

The LTTng project aims at providing highly efficient tracing tools for Linux.
Its tracers help tracking down performance issues and debugging problems
involving multiple concurrent processes and threads. Tracing across multiple
systems is also possible. This toolchain allows integrated kernel and user-space
tracing from a single user interface. It was initially designed and implemented
to reproduce, under tracing, problems occurring in normal conditions. It uses a
linearly scalable and wait-free RCU (Read-Copy Update) synchronization mechanism
and provides zero-copy data extraction. These mechanisms were implemented in
kernel and then ported to user-space as well.
 
Apart from LTTng's kernel tracer and userspace tracer, viewing and analysis
tools are part of the project. In this thesis, we worked with and extended 
\textit{Babeltrace} \footnote{http://lttng.org/babeltrace}.

Apart from the fact LTTng is a complete toolchan that can be easily installed in
almost any Linux distribution and the integrated kernel and user space tracing
offered, we chose LTTng because of its minimal performance overhead. Since it
was initially designed to `reproduce, under tracing, problems occurring in
normal conditions', LTTng was the ideal tool to use for real-time low-overhead,
block-storage tracing with BlkKin.

In order to understand how LTTng manages to have such a good performance, we
have to go through its internals. But first, we give an overview outline of its
architecture and basic components. According to D. Goulet's Master thesis
(\cite{goulet}), LTTng's architecture can be summarized as shown in Figure
\ref{fig:lttng-arch.png}.  

\diagram{LTTng Architecture}{lttng-arch.png}

The \texttt{lttng} command line interface is a small program used to interact
with the session daemon. Possible interaction are creating sessions, enabling
events, starting tracing and so on. The use of this command line tool is further
explained in Chapter \ref{} about how to use BlkKin.

Tracing sessions are used to isolate users from each other and create coherent
tracing data between all tracing sources (Ex: MariaDB vs Kernel). This
\textit{session daemon} routes user commands to the tracers and keeps an
internal state of the requested actions. The daemon makes sure that this
internal state is in complete synchronization with the tracers, and therefore no
direct communication with the tracers is allowed other than via the session
daemon.  This daemon is self-contained between users. Each user can run its own
session daemon but only one is allowed per user. No communication happens
between daemons. 

\textit{Consumer daemons} extract data from buffers containing recorded data and
write it to disk for later analysis. There are two separate consumer daemons,
one handling user space and the second one the kernel. A single consumer daemon
handles all the user space (and similarly for kernel space) tracing sessions for
a given session daemon. It is the session daemon that initiates the execution of
the user space and kernel consumer daemons and feeds them with tracing commands.

LTTng internals define and make use of the following concepts in order to create
an abstraction layer between the user and the tracers.
 
\begin{description}

\item[Domains] 
are essentially a type of tracer or tracer/feature tuple.  Currently, there are
two domains in lttng-tools. The first one is \texttt{UST} which is the global
user space domain. Channels and events registered in that domain are enabled on
all current and future registered user space applications. The other domain is
\texttt{KERNEL}.  Three more domains are not yet implemented but are good
examples of the tracer/feature concept. They are UST PID for specific PID
tracing, UST EXEC NAME based on application name and UST PID FOLLOW CHILDREN
which is the same as tracing a PID but follows spawned children.

\item[Session]
is an isolated container used to separate tracing sources and users from each
other. It takes advantage of the session feature offered by the tracer.  Each
tracing session has a human readable name (Ex.: myapps) and a directory path
where all trace data is written. It also contains the user UID/GID, in order to
handle permissions on the trace data and also determine who can
interact with it. Credentials are passed through UNIX socket for that purpose.

\item[Event] 
relates to a TRACE EVENT statement in your application code or in the Linux
kernel instrumentation.  Using the command line tool \texttt{lttng}, you can
enable and disable events for a specific tracing session on a per domain basis.
An event is always bound to a channel and associated tracing context.

\item[Channel]
is a pipe between an information producer and consumer. They existed in the
earlier LTTng tracers but were hardcoded and specified by the tracer. In the
new LTTng 2.0 version, channels are now definable by the user and completely
customizable (size of buffers, number of subbuffer, read timer, etc.).  A
channel contains a list of user specified events (e.g. system calls and
scheduling switches) and context information (e.g. process id and priority).
Channels are created on a per domain basis, thus each domain contains a list of
channels that the user creates.  Each event type in a session can belong to a
single channel. For example, if event A is enabled in channel 1, it cannot be
enabled in channel 2. However, event A can be enabled in channel 2 (or channel
1 but not both) of another session.

\end{description}

\section{Buffering scheme}\label{sec:buffers}

In this part we analyze the buffering scheme employed by LTTng for efficient
tracing.

As mentioned, a channel is a pipe between an information producer and consumer.
It serves as a buffer to move data efficiently. It consists of one buffer per
CPU to ensure cache locality and eliminate false-sharing. Each buffer is made of
many sub-buffers where slots are reserved sequentially.  A slot is a sub-buffer
region reserved for exclusive write access by a probe.  This space is reserved
to write either a sub-buffer header or an event header and payload. Figure
\ref{fig:buffers.png} shows space being reserved. On CPU 0, space is reserved in
sub-buffer 0 following event 0. 

\diagram{Channel layout}{buffers.png}

In this buffer, the header and event 0 elements have been complelety written to
the buffer. The grey area represents slots for which associated commit count
increment has been done. Committing a reserved slot makes it available for
reading. On CPU n, a slot is reserved in sub-buffer 0 but is still uncommitted.
It is however followed by a committed event. This is possible due to the non
serial nature of event write and commit operations. This situation happens when
execution is interrupted between space reservation and commit count update and
another event must be written by the interrupt handler.  Sub-buffer 1, belonging
to CPU 0, shows a fully committed sub-buffer ready for reading.


Events written in a reserved slot are made of a header and a variable-sized
payload. The header contains information containing the time stamp associated
with the event and the event type (an integer identifier). The event type
information allows parsing the payload and determining its size. The maximum
slot size is bounded by the sub-buffer size. Both the number of the sub-buffers
and their size can be configured by the \texttt{lttng} command line tool.

In order to synchronize the producer and consumer scheme, LTTng makes use of
atomic operations. The two atomic instructions required are the \texttt{CAS}
(Compare-And-Swap) and a simple atomic increment. Each per-CPU buffer has a
control structure which contains the \textit{write count}, the \textit{read
count}, and an array of \textit{commit counts} and \textit{commit seq counters}.
The counters \textit{commit count} keep track of the amount of data committed in
a sub-buffer using a lightweight increment instruction. The \textit{commit seq}
counters are updated with a concurrency-aware synchronization primitive each
time a sub-buffer is filled. The read count is updated using a standard
SMP-aware \texttt{CAS} operation. This is required because the reader thread can
read sub-buffers from buffers belonging to a remote CPU.

In the next two sections we will present how tracing is achieved in the
different domains, kernel and user space.

\section{Kernel-space tracing}\label{sec:kernel-tracing}

In the previous section we described the buffering scheme used by LTTng. In this
chapter we will analyze the kernel mechanism that enables LTTng to add a minimum
overhead to the instrumented application during tracing or when the tracing is
stopped.

In order to trace the Linux kernel with minimum overhead and without hurting the
performance when the tracing is disabled, the equivalent mechanism should be
provided by the kernel. The initial approach of \textit{Kprobes}\cite{kprobes}
Kprobes are a hardware breakpoint-based instrumentation approach. The Kprobe
infrastructure dynamically replaces each kernel instruction to instrument with a
breakpoint, which generates a trap each time the instruction is executed. A
tracing probe can then be executed by the trap handler. However, due to the
heavy performance impact of breakpoints, the inability to extract local
variables anywhere in a function due to compiler optimizations, and the
maintenance burden of keeping instrumentation separate from the kernel code, a
more elaborate solution was needed.

This solution was given by Mathew Desnoyers the Linux Kernel Markers
\cite{kmarkers} and Tracepoints infrastructure. The markers and tracepoints
allow us to declare instrumentation statically at the source-code level without
affecting performance significantly and without adding the cost of a function
call when instrumentation is disabled. A marker placed in code provides a hook
to call a function (probe) that can be provided at runtime. A marker can be
`on' (a probe is connected to it) and the function is called so information is
logged, or `off' (no probe is at- tached). When a marker is `off' it has no
effect, except for adding a tiny time penalty (checking a condition for a
branch). This instrumentation mechanism enables the instrumenta- tion of an
application at the source-code level. Markers con- sists essentially of a C
preprocessing macro which adds, in the instrumented function, a branch over a
function call. By doing so, neither the stack setup nor the function call are
ex- ecuted when the instrumentation is not enabled. At runtime, each marker can
be individually enabled, which makes the branch execute both the stack setup
and the function call 

Having extremely low-overhead when instrumentation is dynamically disabled is
crucially important to provide Linux distributions the incentive to ship
instrumented programs to their customers. Markers and tracepoints consist in a
branch skipping a stack setup and function call when instrumentation is
dynamically disabled (dormant). These individual instrumentation sites can be
enabled dynamically at runtime by dynamic code modification, and only add low
overhead when tracing. The typical overhead of a dormant marker or tracepoint
has been measured to be below 1 cycle \cite{marker-perf} when cache-hot. Static
declaration of tracepoints helps manage this instrumentation within the Linux
kernel source-code. Given that the Linux kernel is a distributed collaborative
project, enabling each kernel subsystem instrumentation to be maintained by
separate maintainers helps distributing the burden of managing kernel-wide
instrumentation.  

However, statically declaring an instrumentation site for dynamic activation
typically incurs a non-zero performance overhead due to the test and branch
required to skip the instrumentation call. To overcome this limitation,
Desnoyers created the concept of activating statically compiled code
efficiently by dynamically modifying an immediate operand within an
instruction, which is called Immediate Values \cite{marker-perf}. This
mechanism replaces the standard memory read, loading the condition variable, by
a constant folded in the immediate value encoding of an instruction operand.
This removes any data memory access to test for disabled instrumentation by
keeping all the information encoded in the instruction stream. However, this
involves dynamically modifying code safely against concurrent multiprocessor
accesses. This requires either stopping all processors for the duration of the
modification, or using a more complex, yet more lightweight, core
synchronization mechanism. The choice made was the temporary breakpoint bypass
\cite{bp-bypass}.

In order to overcome a Kernel Markers' drawback, which was the limited type
verification to scalar types due because its API is based on format string,
\textit{Tracepoints}
\footnote{https://www.kernel.org/doc/Documentation/trace/tracepoints.txt} were
created.

Two elements are required for tracepoints :
\begin{itemize}
\item A tracepoint definition, placed in a header file.
\item The tracepoint statement, in C code.
\end{itemize}

In order to use tracepoints, you should include \texttt{linux/tracepoint.h}.

Define an event in \texttt{include/trace/events/subsys.h} as shown in Listing
\ref{lst:kernel-event.h}. You can use the Tracepoint within kernel code as shown
in Listing \ref{lst:kernel-use.c}.

\ccode{Kernel event definition}{kernel-event.h}
\ccode{Kernel Tracepoint activation}{kernel-use.c}

As far as LTTng is concerned, the traced data is entirely controlled by the
kernel. According to \cite{desnoyer}, the kernel exposes a transport pipeline
(Ex: character device or anonymous file descriptor) and a user space daemon
(session daemon) simply extracts data through this mechanism. This mechanism is
based on \texttt{DebugFS}
\footnote{https://www.kernel.org/doc/Documentation/filesystems/debugfs.txt}

\section{User-space tracing}\label{sec:user-tracing}

User-space tracing needs a different approach from kernel-tracing. Approaches
like SystemTap\footnote{https://sourceware.org/systemtap/} or
DTrace\footnote{http://dtrace.org/blogs/} based user-space tracing on
breakpoints or system-calls whenever a tracing point is reached. However, this
has a severe performance impact on the instrumented application and makes them
inappropriate for system monitoring. 

During BlkKin implementation, we tried to implement a custom tracing mechanism
based on a memory-mapped ring buffer. However, this mechanism should handle with
all the consumer-producer concurrency issues. Inspecting the LTTng user-space
tracer, we found out that the aforementioned buffering scheme (\ref{sec:buffers}
is implemented for user-space tracing as well. This mechanism is not based on
breakpoints or system-calls and does not affect the system's performance. So we
decided to base out backend on LTTng ust-trace. 

While the kernel tracer is the most complex entity in terms of code and
algorithms, it is the simplest to handle. For the session daemon, this tracer is
a single tracing source. However, tracing in user-space sets challenges
concerning multiple users and concurrency. D. Goulet in his master thesis
\cite{goulet} created the \texttt{lttng-tools} project, which provides the
needed unified user and kernel tracing. This project handles with all the issues
concerning multiple concurrent tracing sources and the mechanism for their
synchronization.

Since all these problems are handled by LTTng, in this section we will describe
the mechanism behind a single tracing session.

\diagram{User-space tracer architecture}{ust-architecture.png}

As seen in Figure \ref{fig:ust-architecture.png}, each instrumented application
creates a dedicated thread for tracing. This thread communicated with the
sessiond over a UNIX-domain socket. The creation of this dedicated thread is
created when the instrumented application is launched. Its creation is coded
within functions labeled with \texttt{\_\_attribute\_\_((constructor))}. The
instrumented applications are dynamically linked with the ust libraries. So,
when the object files are loaded, the specific code is executed and the threads
are created. The session daemon communicates with the consumer over a
UNIX-domain socket. Over this path pass all the control messages. For example,
over these UNIX sockets pass the file descriptors of the shared memory segment,
so that the consumer and the instrumented application refer to the same segment.
The elaborate buffering scheme is deployed on a shared memory segment. The
synchronization issues for the access to the segment are handled by the
\texttt{liburcu}\footnote{https://lttng.org/urcu}. Whenever there are data
available, the instrumented application notifies the consumer over a UNIX pipe.
After that the consumer (which is different from the kernel consumer), writes
the tracing data to a local folder. The tracing data will be available for
viewing using viewers like Babeltratrace\footnote{https://lttng.org/babeltrace}
or LTTTV\footnote{https://lttng.org/lttv} only after the end of the session.
This will be furthered discussed in Section \ref{sec:ctf}.

The mechanism that supports the Tracepoints was ported in user-space as well, as
mentioned in \cite{userspace-markers}. The user-space Tracepoints are defined in
a header file. This file is compiled into an object file, which is finally
linked along with the \texttt{liblttng-ust} with the instrumented application.
So, the tracing threads will be created as mentioned and the tracepoint function
calls, will trace information only when tracing is enabled.

\section{Common Trace Format (CTF)}\label{sec:ctf}

LTTng makes use of \textit{Common Trace Format}
(CTF)\footnote{http://www.efficios.com/ctf} for the traces created. CTF is a
trace format based on the requirements of the industry. It is the result of the
collaboration between the Multicore
assosication\footnote{http://www.multicore-association.org/} and the Linux
community. This format was created to cover the tracing needs from versatile
communities like the embedded, telecom, high-performance and kernel communities.
It is a  high-level model meant to be an industry-wide, common model, fulfilling
the tracing requirements. It is meant to be application-, architecture-, and
language-agnostic. One major element of CTF is the Trace Stream Description
Language (TSDL) which flexibility enables description of various binary trace
stream layouts. The CTF format is formally described in RFC.

According to this abstract model:

A \textit{trace} is divided into multiple event streams. Each event stream
contains a subset of the trace event types. The final output of the trace, after
its generation and optional transport over the network, is expected to be either
on permanent or temporary storage in a virtual file system. Because each event
stream is appended to while a trace is being recorded, each is associated with a
distinct set of files for output. Therefore, a stored trace can be represented
as a directory containing zero, one or more files per stream.

An \textit{event stream} can be divided into contiguous event packets of
variable size. An event packet can contain a certain amount of padding at the
end. The stream header is repeated at the beginning of each event packet

CTF offers a variety of \textit{data types} for tracing, like integers, arrays
or strings, which are defined in the RFC. Τhese types allow inheritance so
that other types can be derived. 

So an event representation in CTF consists of 

The overall structure of an event is:

\begin{description}
\item[Event Header] \hfill \\
(as specified by the stream meta-data). These information are the same for all
streams in the trace. Example information: trace UUID
\item[Stream Event Context] \hfill \\ 
(as specified by the stream meta-data) The stream context is applied to all
events within the stream. Example information: pid, payload size
\item[Event Context] \hfill \\
(as specified by the event meta-data) The event context contains information
relative to the current event. Example information: missing fields
\item[Event Payload] \hfill \\
(as specified by the event meta-data) An event payload contains fields specific
to a given event type
\end{description}

Each trace is associated with some metadata. For example, the trace stream
layout description is located in the trace meta-data or the fields belonging to
an event type are described in the event-specific meta-data. The meta-data is
itself located in a separate stream identified by its name: `metadata'.


The fact that the trace metadata are located in a different stream, prevents an
LTTng `local' trace from being read (reliably) without stopping the tracing
session. LTTng offers no guarantee that the metadata on disk contains all the
layout information needed to read any packet previously flushed to disk. For
example, a new application, instrumented with previously unknown events, could
be launched and fill a buffer with events. That buffer would then be flushed to
disk. At that point, there would be no guarantee that the lttng-sessiond would
have had the chance to flush the updated metadata to disk. Thus, reading that
trace would fail.

So, in order to read an LTTng CTF-formatted event, LTTng created \texttt{relayd}
and enabled live tracing, which is furthered analyzed in Section
\ref{sec:relayd}.

\section{Live tracing}\label{sec:relayd}

In version 2.4.0 LTTng integrated live tracing support. Instead of waiting the
end of the session in order to read the traces, lttng-live enabled developers to
read the traces live while they are being created using Babeltrace. 

In order to live read trace data, traces have to be streamed, even if the tracer
and the viewer operate on the same machine. Live tracing is achieved through the
use of special daemon called \texttt{relayd}. So, when creating the tracing
session, you can define whether you prefer live tracing and then you have to
provide the IP address of the realyd which runs on the remote machine. When the
session starts, relayd stores data to the remote machine, so that they will be
saved after the end of the session. In order to view the traces, you have to use
Babeltrace which connects to the relayd and prints text data to the stdout, when
they arrive over the network. Again Babeltrace can run on different machine from
the one being traced and the one where relayd runs.

LTTng relayd handles with the previous-mentioned metadata inconsistencies.
Whenever new events appear, when a new instrumented application is launched for
example, the relayd updates the metadata accordingly. As a result, the viewer
(Babeltrace) receives from relayd a data packet with the actual tracing
information and an index packet to properly locate the information. The updated
metadata are also streamed to the client in a separate stream, as already
mentioned. At any point, the live client must have all the metadata associated
with the data packets it receives. The resulting interconnection is seen in
Figure \ref{fig:relayd.png}.

\diagram{LTTng live tracing}{relayd.png} 
